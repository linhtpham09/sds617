{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&DS 617 Applied Machine Learning and Causal Inference Research Seminar: Assignment 2\n",
    "\n",
    "**Deadline**\n",
    "\n",
    "Assignment 2 is due Monday, March 24th at 1:30pm. Late work will not be accepted.\n",
    "\n",
    "\n",
    "**Submission**\n",
    "\n",
    "Submit your assignment as a .pdf on Gradescope. On Gradescope, there are 2 assignments, one where you will submit a pdf file and one where you will submit the corresponding .ipynb that generated it. \n",
    "Note: The problems in each homework assignment are numbered.When submitting the pdf on Gradescope, please select the correct pages that correspond to each problem. \n",
    "\n",
    "To produce the .pdf, do the following to preserve the cell structure of the notebook:\n",
    "- Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "- Under \"Download as\", select \"HTML (.html)\"\n",
    "- After the .html has downloaded, open it and then select \"File\" and \"Print\"\n",
    "- From the print window, select the option to save as a .pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "In this exercise, we'll employ different prompt tuning techniques on GSM8k dataset [Link](https://github.com/openai/grade-school-math/tree/master/grade_school_math/data).\n",
    "\n",
    "The GSM8K dataset is an OpenAI-curated collection of 8,500 grade school math problems designed to challenge and evaluate the mathematical reasoning capabilities of language models. It contains approximately 7,500 training and 1,000 test problems that require 2 to 8 steps to solve, using basic arithmetic operations. The dataset aims to diagnose current model limitations in multi-step reasoning and supports advancements in AI's understanding and processing of natural language math problems. It includes both standard problems and a Socratic format with guiding subquestions, along with calculation annotations to aid in accuracy, making it a valuable resource for AI research in natural language processing.\n",
    "\n",
    "Below, we have provided helper functions to load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load data from a URL\n",
    "def load_data_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = [json.loads(line) for line in response.iter_lines(decode_unicode=True)]\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to download the file: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to get the true solution from JSON file \n",
    "def extract_solution(problem):\n",
    "    \"\"\"\n",
    "    Extracts the final numeric solution from a problem dictionary with 'question' and 'answer' keys.\n",
    "    The answer is expected to contain a '####' token followed by the final numeric solution.\n",
    "    \n",
    "    :param problem: A dictionary with 'question' and 'answer' keys.\n",
    "    :return: The final numeric solution as a string.\n",
    "    \"\"\"\n",
    "    # Split the answer into lines\n",
    "    answer_lines = problem['answer'].split('\\n')\n",
    "    # Look for the line with the '####' token\n",
    "    for line in answer_lines:\n",
    "        if '####' in line:\n",
    "            # Extract the numeric solution that follows the '####' token\n",
    "            solution = line.split('####')[-1].strip()\n",
    "            return solution\n",
    "    # If no solution is found, return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URLs for the train and test data\n",
    "train_url = \"https://raw.githubusercontent.com/openai/grade-school-math/master/grade_school_math/data/train.jsonl\"\n",
    "test_url = \"https://raw.githubusercontent.com/openai/grade-school-math/master/grade_school_math/data/test.jsonl\"\n",
    "\n",
    "# Load the training data\n",
    "df_train = load_data_from_url(train_url)\n",
    "df_train = df_train.sample(n=1000, random_state=928)\n",
    "\n",
    "# Load the test data\n",
    "df_test = load_data_from_url(test_url)\n",
    "df_test = df_test.sample(n=500, random_state=184)\n",
    "\n",
    "# Display the lengths of the datasets as a check\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question    Taegan goes to a carnival where she wins ticke...\n",
      "answer      If tickets are valued at $3 then in total, Tae...\n",
      "Name: 3103, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sample_row = df_train.iloc[0,] \n",
    "print(sample_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Taegan goes to a carnival where she wins tickets from each of the 5 carnival games and also finds 5 tickets on the floor. Each ticket is worth $3. In total, she has tickets that total a value of $30. If Taegan won an equal number of tickets from each of the games, how many tickets did she win from each game?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row['question'] # sample question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the solution\n",
    "extract_solution(sample_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implement zero shot learning, few shot learning, and chain of thought prompting using gpt-4o. Make a figure or table comparing the accuracy of each on the test set and comment on your results and whether they align with your expectations. Sample at most 1000 observations. Again, remember to start with a smaller subset of your dataset to ensure your implementation is correct before scaling up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)  Explore recent literature for reasoning methods that could enhance the performance of CoT and improve the baseline obtained in a). Then, compare the results with the reasoning models o1 and o3, and discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Perform an ablation study similar to that of Section 3.3 of Wei et al. 2023: [Link](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf). Comment on your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
